# üå± Equipo3ETL

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-12+-green.svg)](https://www.postgresql.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-orange.svg)](https://github.com/features/actions)

üìä Sistema ETL completo para integrar, limpiar y unificar datos provenientes de diferentes fuentes utilizadas en la **agroindustria de la ca√±a de az√∫car**.

> üéØ **Proyecto desarrollado como parte del curso de ETL - 2025**

---

## üë• Integrantes

- **Andres David Bola√±os Paz** - [@AndresBPaz](https://github.com/AndresBPaz)
- **Santiago Correa Campa√±a**
- **Jhonatan Andres Tapia Cordoba** - [@JhonatanTC99](https://github.com/JhonatanTC99)
- **Juan Jose Betancourt Osorio** - [@juanjo44](https://github.com/juanjo44)

---

## üìë Tabla de Contenidos

- [‚ú® Caracter√≠sticas](#-caracter√≠sticas)
- [üèóÔ∏è Arquitectura](#Ô∏è-arquitectura)
- [‚öôÔ∏è Instalaci√≥n](#Ô∏è-instalaci√≥n)
- [üìÇ Estructura del Proyecto](#-estructura-del-proyecto)
- [üîß Configuraci√≥n](#-configuraci√≥n)
- [üöÄ Uso](#-uso)
- [üìä Dashboard](#-dashboard)
- [üîÑ CI/CD con GitHub Actions](#-cicd-con-github-actions)
- [üß© Transformaciones](#-transformaciones)
- [üóÑÔ∏è Base de Datos](#Ô∏è-base-de-datos)

---

## ‚ú® Caracter√≠sticas

### Pipeline ETL Completo

- ‚úÖ **Extracci√≥n**: Lectura de m√∫ltiples archivos Excel (.xlsx, .xlsm)
- ‚úÖ **Transformaci√≥n**: Limpieza, filtrado y normalizaci√≥n de datos declarativa
- ‚úÖ **Carga**: Almacenamiento en PostgreSQL con esquema normalizado
- ‚úÖ **Exportaci√≥n**: Salidas en formato Parquet y CSV

### Datasets Procesados

1. **Abastecimientos** - Consumo de combustible por equipo
2. **Actividades** - Productividad de trabajadores por actividad
3. **Insumos** - Costos de insumos por hect√°rea
4. **Reporte Maquinaria** - Eficiencia de equipos y horas de trabajo

### Dashboard Interactivo

- üìà Visualizaciones con Plotly Express
- üîç Filtros din√°micos y reactivos
- ‚ö° Cache inteligente con actualizaci√≥n autom√°tica
- üì± Dise√±o responsive

### Automatizaci√≥n

- ü§ñ CI/CD con GitHub Actions
- üêò PostgreSQL como servicio en tests
- ‚úÖ Validaci√≥n autom√°tica de datos

---

## üèóÔ∏è Arquitectura

```

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Excel Files    ‚îÇ
‚îÇ  (.xlsx/.xlsm)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ
‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Extract       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ loaders.py
‚îÇ   (pandas)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ
‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Transform     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ transforms.py
‚îÇ   (clean/filter)‚îÇ      + settings.yaml
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Parquet Files
‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ CSV Files
‚îÇ
‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Load          ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ CSVLoader.py
‚îÇ   (PostgreSQL)  ‚îÇ      + conexiondb.py
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ
‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Visualize     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ plots.py
‚îÇ   (Streamlit)   ‚îÇ      + Plotly
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

```

---

## ‚öôÔ∏è Instalaci√≥n

### Requisitos Previos

- **Python 3.8+**
- **PostgreSQL 12+** (opcional, solo para carga a DB)
- **Git**

### Pasos de Instalaci√≥n

1. **Clonar el repositorio**

```

git clone https://github.com/AndresBPaz/Equipo3ETL.git
cd Equipo3ETL

```

2. **Crear y activar entorno virtual**

**macOS/Linux:**
```

python -m venv .venv
source .venv/bin/activate

```

**Windows:**
```

python -m venv .venv
.venv\Scripts\activate

```

3. **Instalar dependencias**

```

pip install -e .

```

4. **Configurar variables de entorno** (para desarrollo local con DB)

Crear archivo `.env`:

```

DB_HOST=localhost
DB_PORT=5432
DB_NAME=mydb
DB_USER=postgres
DB_PASSW=tu_password

```

---

## üìÇ Estructura del Proyecto

```

Equipo3ETL/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ etl.yml              \# CI/CD con GitHub Actions
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ secrets.toml            \# Secrets para Streamlit (no subir a Git)
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.yaml           \# Configuraci√≥n declarativa del ETL
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    \# Archivos Excel fuente
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ abastecimientos/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ actividades/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ insumos/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rep_maquinaria/
‚îÇ   ‚îî‚îÄ‚îÄ processed/              \# Archivos transformados (Parquet/CSV)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ run_all.py             \# Ejecutar todos los pipelines
‚îÇ   ‚îú‚îÄ‚îÄ loadData.py            \# Cargar datos a PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ run_abastecimientos.py
‚îÇ   ‚îú‚îÄ‚îÄ run_actividades.py
‚îÇ   ‚îú‚îÄ‚îÄ run_insumos.py
‚îÇ   ‚îî‚îÄ‚îÄ run_rep_maquina.py
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ etl_project/
‚îÇ       ‚îú‚îÄ‚îÄ config.py          \# Gesti√≥n de configuraci√≥n
‚îÇ       ‚îú‚îÄ‚îÄ conexiondb.py      \# Conexi√≥n PostgreSQL con reintentos
‚îÇ       ‚îú‚îÄ‚îÄ CSVLoader.py       \# Carga de CSVs a base de datos
‚îÇ       ‚îú‚îÄ‚îÄ loaders.py         \# Lectura de archivos Excel
‚îÇ       ‚îú‚îÄ‚îÄ transforms.py      \# Funciones de transformaci√≥n
‚îÇ       ‚îú‚îÄ‚îÄ pipelines/         \# Pipelines por dataset
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ abastecimientos.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ actividades.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ insumos.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ rep_maquinaria.py
‚îÇ       ‚îî‚îÄ‚îÄ views/
‚îÇ           ‚îî‚îÄ‚îÄ plots.py       \# Dashboard Streamlit
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ pyproject.toml             \# Dependencias y metadata
‚îî‚îÄ‚îÄ README.md

```

---

## üîß Configuraci√≥n

### Archivo `config/settings.yaml`

Define toda la configuraci√≥n del ETL de manera declarativa:

```

database:
HOST: localhost
PORT: 5432
DB_NAME: mydb
USER: postgres
PASSWORD: ""

paths:
data_raw: "data/raw/"
data_processed: "data/processed/"

datasets:
abastecimientos:
source:
folder: "data/raw/abastecimientos/"
patterns: ["*.xlsx", "*.xlsm"]
transforms:
clean_columns: true
drop_columns: [material, texto_breve_de_material]
filters:
- { column: clase_de_movimiento, op: equals, value: 261 }
rename:
"fe.contabilizaci√≥n": fecha
orden: equipo
derive:
delete_first_n:
column: equipo
n: 3

```

### Prioridad de Variables

El sistema carga configuraci√≥n en este orden:

1. **Variables de entorno** (`os.environ`)
2. **Streamlit secrets** (`st.secrets`)
3. **Archivo YAML** (`config/settings.yaml`)

---

## üöÄ Uso

### 1. Ejecutar Pipeline Completo

Procesar todos los datasets:

```

python scripts/run_all.py

```

Esto genera archivos en `data/processed/`:
- `abastecimientos.parquet` / `abastecimientos.csv`
- `actividades.parquet` / `actividades.csv`
- `insumos.parquet` / `insumos.csv`
- `rep_maquinaria.parquet` / `rep_maquinaria.csv`

### 2. Ejecutar Pipeline Individual

```

python scripts/run_abastecimientos.py
python scripts/run_actividades.py
python scripts/run_insumos.py
python scripts/run_rep_maquina.py

```

### 3. Cargar Datos a PostgreSQL

**Requisito**: PostgreSQL corriendo y credenciales configuradas.

```

python scripts/loadData.py

```

### 4. Ejecutar Dashboard Localmente

```

streamlit run src/etl_project/views/plots.py

```

Dashboard disponible en: `http://localhost:8501`

---

## üìä Dashboard

### Visualizaciones Disponibles

1. **üìà Productividad por Actividad**
   - Gr√°fico de barras con total producido
   - Filtros: trabajador, actividad
   - Hover: empresa, cantidad registros, promedio

2. **üí∞ Costo de Insumos por Hect√°rea**
   - Gr√°fico de l√≠neas temporal
   - Filtros: hacienda, actividad
   - Hover: costo total, √°rea total

3. **üöú Producci√≥n por Maquinaria**
   - Gr√°fico de barras por actividad
   - Filtros: actividad maquinaria
   - Hover: producci√≥n total, horas totales

4. **‚õΩ Combustible por Unidad Producida**
   - Gr√°fico de l√≠neas mensual
   - Filtros: mes
   - Hover: galones totales, producci√≥n total

### Desplegar en Streamlit Community Cloud

1. **Crear `.streamlit/secrets.toml`** (local, no subir a Git):

```

[connections.postgresql]
dialect = "postgresql"
host = "tu-host.com"
port = 5432
database = "mydb"
username = "tu_usuario"
password = "tu_password"

```

2. **Conectar repositorio en Streamlit Cloud**

3. **Configurar secrets** en el panel de Streamlit:
   - Settings > Secrets
   - Pegar contenido de `secrets.toml`

4. **Deploy autom√°tico** ‚úÖ

---

## üîÑ CI/CD con GitHub Actions

El workflow `.github/workflows/etl.yml` ejecuta autom√°ticamente:

### En cada Push/PR a `main`:

‚úÖ Configura PostgreSQL como servicio
‚úÖ Instala dependencias Python
‚úÖ Ejecuta pipeline de transformaci√≥n (`run_all.py`)
‚úÖ Carga datos a PostgreSQL de prueba (`loadData.py`)
‚úÖ Valida conexiones y esquemas

### Configuraci√≥n del Workflow

```

services:
postgres:
image: postgres:15
env:
POSTGRES_USER: testuser
POSTGRES_PASSWORD: testpass
POSTGRES_DB: mydb
ports:
- 5432:5432
options: >-
--health-cmd "pg_isready"
--health-interval 10s
--health-timeout 5s
--health-retries 10

```

---

## üß© Transformaciones

### Funciones Disponibles

| Funci√≥n | Descripci√≥n | Ejemplo |
|---------|-------------|---------|
| `clean_column_names(df)` | Normaliza nombres de columnas | `fecha_inicio` |
| `drop_columns(df, cols)` | Elimina columnas | `['col1', 'col2']` |
| `filter_value(df, col, val, op)` | Filtros condicionales | `op='equals'` |
| `delete_first_n(df, col, n)` | Recorta caracteres iniciales | `n=3` |
| `concat_columns(df, new, cols, sep)` | Concatena columnas | `sep='_'` |
| `adjust_date_format(df, col, fmt_in, fmt_out)` | Transforma fechas | `'%d/%m/%Y'` |

### Operadores de Filtro

- `equals`: Igualdad exacta
- `not_equals`: Diferente de
- `in`: Contenido en lista
- `not_in`: No contenido en lista
- `greater_than`: Mayor que
- `less_than`: Menor que
- `between`: Entre dos valores

### Ejemplo de Uso

```

from etl_project.transforms import clean_column_names, filter_value

# Limpiar nombres

df = clean_column_names(df)

# Filtrar movimientos tipo 261

df = filter_value(df, "clase_de_movimiento", 261, "equals")

# Filtrar centros de costo < 20000000

df = filter_value(df, "centro_de_coste", 20000000, "less_than")

```

---

## üóÑÔ∏è Base de Datos

### Esquema PostgreSQL

```

-- Esquema raw: datos originales
CREATE SCHEMA IF NOT EXISTS raw;

CREATE TABLE raw.abastecimientos (...);
CREATE TABLE raw.actividades (...);
CREATE TABLE raw.insumos (...);
CREATE TABLE raw.rep_maquinaria (...);

-- Esquema stage: vistas anal√≠ticas
CREATE SCHEMA IF NOT EXISTS stage;

CREATE VIEW stage.vista_productividad_trabajador AS
SELECT
trabajador,
actividad,
empresa,
SUM(produccion) as total_producido,
COUNT(*) as cantidad_registros,
AVG(produccion) as promedio_produccion
FROM raw.actividades
GROUP BY trabajador, actividad, empresa;

-- Otras vistas...

```

### Conexi√≥n a la Base de Datos

```

from etl_project.conexiondb import DatabaseConnection
import pandas as pd

# Obtener conexi√≥n

db = DatabaseConnection()
engine = db.get_engine()

# Ejecutar query

df = pd.read_sql("SELECT * FROM raw.abastecimientos LIMIT 10", con=engine)

# Cerrar conexi√≥n

db.close()

```

---

## üìù Mejores Pr√°cticas

### Desarrollo Local

1. Usar entorno virtual siempre
2. No subir `data/` a Git (agregado a `.gitignore`)
3. Probar pipelines individualmente antes de `run_all.py`
4. Validar salidas en `data/processed/`

### Producci√≥n

1. Configurar secrets correctamente
2. Validar healthchecks de PostgreSQL
3. Monitorear logs de GitHub Actions
4. Documentar cambios en configuraci√≥n YAML

---

## ü§ù Contribuir

### Workflow

1. Fork el repositorio
2. Crear rama: `git checkout -b feature/nueva-funcionalidad`
3. Commit: `git commit -m 'Agrega nueva funcionalidad'`
4. Push: `git push origin feature/nueva-funcionalidad`
5. Abrir Pull Request

### Est√°ndares

- ‚úÖ Usar type hints en funciones
- ‚úÖ Documentar con docstrings
- ‚úÖ Seguir PEP 8
- ‚úÖ Agregar tests para nuevas features

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver [LICENSE](LICENSE) para detalles.

---

## üôè Agradecimientos

- Universidad por el apoyo acad√©mico
- Comunidad open-source por las herramientas
- Instructores por la gu√≠a en el desarrollo ETL

---

## üìû Contacto

**Andres Bola√±os** - [@AndresBPaz](https://github.com/AndresBPaz)

---

<div align="center">

‚≠ê **Si este proyecto te fue √∫til, dale una estrella** ‚≠ê

Hecho con ‚ù§Ô∏è por el Equipo 3

</div>