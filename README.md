# ğŸŒ± Equipo3ETL

ğŸ“Š Este repositorio contiene el desarrollo de un proceso **ETL** (Extract, Transform, Load) diseÃ±ado para integrar, limpiar y unificar datos provenientes de diferentes fuentes utilizadas en la **agroindustria de la caÃ±a de azÃºcar**.

ğŸ‘¥ **Integrantes**  
- Andres David BolaÃ±os Paz  
- Santiago Correa CampaÃ±a  
- Jhonatan Andres Tapia Cordoba  
- Juan Jose Betancourt Osorio  

---

## ğŸ“‘ Ãndice

- [âš™ï¸ InstalaciÃ³n de dependencias](#ï¸-instalaciÃ³n-de-dependencias)
- [ğŸ“˜ DescripciÃ³n](#-descripciÃ³n)
- [ğŸ“‚ Estructura](#-estructura)
- [ğŸ”§ ConfiguraciÃ³n](#-configuraciÃ³n)
- [ğŸš€ Pipelines](#-pipelines)
- [â–¶ï¸ EjecuciÃ³n](#ï¸-ejecuciÃ³n)
- [ğŸ“¤ Salidas](#-salidas)
- [ğŸ§© Transformaciones](#-transformaciones)
- [ğŸ“… Fechas y formatos](#-fechas-y-formatos)
- [ğŸ“ Notas de uso de archivos](#-notas-de-uso-de-archivos)

---

## âš™ï¸ InstalaciÃ³n de dependencias

- Requisitos: **Python 3.8 o superior** (segÃºn `requires-python` en `pyproject.toml`).  
- Crear y activar un entorno virtual.  
- Instalar el proyecto desde la raÃ­z para resolver automÃ¡ticamente las dependencias de `pyproject.toml`.  

### ğŸ”¹ Pasos sugeridos:

**macOS/Linux**
```bash
python -m venv .venv
source .venv/bin/activate
```

**Windows**
```bash
python -m venv .venv
.venv\Scripts\activate
```

**Instalar el proyecto**
```bash
# InstalaciÃ³n editable (recomendada durante el desarrollo)
pip install -e .

# InstalaciÃ³n normal
pip install .
```

---

## ğŸ“˜ DescripciÃ³n

- Proyecto **ETL declarativo**: lectura, transformaciones y salidas por dataset definidas en `config/settings.yaml`.  
- Lectura de Excel con `pandas.read_excel` (engine=`openpyxl`) y exportaciÃ³n en **Parquet** y **CSV**.  
- EjecuciÃ³n modular (por dataset) y con un **orquestador** para correr todos los flujos en secuencia.  

---

## ğŸ“‚ Estructura

```text
etl-project/
â”œâ”€ config/
â”‚  â””â”€ settings.yaml
â”œâ”€ data/
â”‚  â”œâ”€ raw/
â”‚  â”‚  â”œâ”€ abastecimientos/
â”‚  â”‚  â”œâ”€ actividades/
â”‚  â”‚  â”œâ”€ insumos/
â”‚  â”‚  â””â”€ rep_maquinaria/
â”‚  â””â”€ processed/
â”œâ”€ scripts/
â”‚  â”œâ”€ run_abastecimientos.py
â”‚  â”œâ”€ run_actividades.py
â”‚  â”œâ”€ run_insumos.py
â”‚  â”œâ”€ run_rep_maquina.py
â”‚  â””â”€ run_all.py
â”œâ”€ src/
â”‚  â””â”€ etl_project/
â”‚     â”œâ”€ loaders.py
â”‚     â”œâ”€ transforms.py
â”‚     â””â”€ pipelines/
â”‚        â”œâ”€ abastecimientos.py
â”‚        â”œâ”€ actividades.py
â”‚        â”œâ”€ insumos.py
â”‚        â””â”€ rep_maquinaria.py
â”œâ”€ pyproject.toml
â””â”€ README.md
```

---

## ğŸ”§ ConfiguraciÃ³n

El archivo `config/settings.yaml` define:

- ğŸ“‚ Paths base  
- ğŸ“‘ ParÃ¡metros de lectura Excel (`engine`, `header`)  
- ğŸ“Š Datasets:  
  - **source** (carpeta, patrones)  
  - **transforms** (clean, drop, rename, filters, derive)  

ğŸ“¥ La lectura usa `pandas.read_excel` con `engine=openpyxl`.  
ğŸ“¤ Las salidas se escriben en `data/processed/` como **Parquet** y **CSV**.  

---

## ğŸš€ Pipelines

- **abastecimientos** â†’ Limpieza de columnas, filtros declarados, renombrado y recorte de prefijos de equipo.  
- **actividades** â†’ Limpieza, filtros, renombrado, ajuste de fechas y generaciÃ³n de IDs concatenados.  
- **insumos** â†’ Limpieza, eliminaciÃ³n de campos, renombrado de fecha, derivaciÃ³n de hacienda e IDs.  
- **rep_maquinaria** â†’ Limpieza, eliminaciÃ³n de campos no usados, renombrado de campos, ajuste de fechas e IDs.  

---

## â–¶ï¸ EjecuciÃ³n

Ejecutar por dataset:

```bash
python scripts/run_abastecimientos.py
python scripts/run_actividades.py
python scripts/run_insumos.py
python scripts/run_rep_maquina.py
```

Ejecutar todo el flujo:

```bash
python scripts/run_all.py
```

Ejecutar carga a base de datos. 

```bash
python scripts/loadData.py
```
---

## ğŸ“¤ Salidas

- **Parquet** â†’ `data/processed/{dataset}.parquet` (requiere `pyarrow` o `fastparquet`).  
- **CSV** â†’ `data/processed/{dataset}.csv` (se puede forzar el formato de fechas con `date_format`).  

---

## ğŸ§© Transformaciones

Funciones principales:

- `clean_column_names(df)` â†’ estandariza nombres de columnas.  
- `drop_columns(df, cols)` â†’ elimina columnas existentes (ignora las ausentes).  
- `filter_value(df, column, value, cmp)` â†’ filtros (`equals`, `not_equals`, `in`, `between`, etc).  
- `delete_first_n(df, column, n)` â†’ recorta caracteres iniciales.  
- `concat_columns(df, new_column, columns, sep, position)` â†’ concatena columnas como string.  
- `concat_column_with_first_n(...)` â†’ nueva columna a partir de primeros `n` caracteres.  
- `adjust_date_format(...)` â†’ transforma fechas entre formatos.  

---

## ğŸ“… Fechas y formatos

En la pipeline se recomienda:

```python
adjust_date_format(
    df,
    column_name="fecha",
    current_format="%d/%m/%Y %I:%M:%S %p",
    desired_format="%d/%m/%Y"
)
```

Al exportar CSV:

```python
df.to_csv("ruta.csv", index=False, encoding="utf-8", date_format="%d/%m/%Y")
```

---

Visualizar los datos. 
```python
./venv/bin/python './src/etl_project/views/plots.py'
streamlit run ./src/etl_project/views/plots.py
```